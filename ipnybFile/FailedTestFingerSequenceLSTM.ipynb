{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout, Masking, TimeDistributed, Bidirectional  # Import Bidirectional\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.callbacks import EarlyStopping # Import EarlyStopping\n"
      ],
      "metadata": {
        "id": "z2oUwAOej6XT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load the JSON Data\n",
        "with open(\"/content/finger_sequences.json\", \"r\") as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# 2. Prepare Data & Labels\n",
        "labels = []\n",
        "sequences = []\n",
        "\n",
        "for label, instances in data.items():\n",
        "    for sequence in instances:\n",
        "        finger_ids = [int(pair[0]) for pair in sequence]  # Convert finger ID to int\n",
        "        durations = [pair[1] for pair in sequence]  # Extract duration times\n",
        "\n",
        "        # Append sequence and corresponding label\n",
        "        sequences.append(list(zip(finger_ids, durations)))\n",
        "        labels.append(label)"
      ],
      "metadata": {
        "id": "47svaJNykDJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Convert Labels to Numeric\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)  # Convert labels to integers"
      ],
      "metadata": {
        "id": "f5mLwVfHkHOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Padding"
      ],
      "metadata": {
        "id": "lOGqRWFK42tN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y4tUr2Zg45bB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "durations = [dur for seq in sequences for _, dur in seq]  # Extract all durations\n",
        "mean_duration = np.mean(durations)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "giLD45pa4555"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "def custom_pad_sequences(sequences, maxlen, padding='post', dtype='float32'):\n",
        "  \"\"\"Pads sequences with custom values based on label.\n",
        "\n",
        "  Args:\n",
        "    sequences: The list of sequences to pad.\n",
        "    maxlen: The desired length for all sequences.\n",
        "    padding: 'pre' or 'post' (default 'post').\n",
        "    dtype: The data type of the padded sequences.\n",
        "\n",
        "  Returns:\n",
        "    A NumPy array of padded sequences.\n",
        "  \"\"\"\n",
        "  padded_sequences = []\n",
        "  for i, seq in enumerate(sequences):  # Use enumerate to get index i\n",
        "    # Determine padding element based on corresponding label\n",
        "    label = labels[i]  # Get label for the sequence\n",
        "    if label == 'CallHarisVai':\n",
        "      padding_element = (\"2\", mean_duration)  # Using finger_map dictionary\n",
        "    elif label == 'Noise':\n",
        "      padding_element = (\"1\", mean_duration)  # Using finger_map dictionary\n",
        "    elif label == 'LikeMe':\n",
        "      padding_element = (\"3\", mean_duration)  # Using finger_map dictionary\n",
        "    elif label == 'ComeCLose':\n",
        "      padding_element = (\"8\", mean_duration)  # Using finger_map dictionary\n",
        "    else:\n",
        "      padding_element = (int(-1), mean_duration)  # Default padding element\n",
        "\n",
        "    # Pad the sequence to the desired length\n",
        "    if len(seq) < maxlen:\n",
        "      padding_elements = [padding_element] * (maxlen - len(seq))\n",
        "      if padding == 'pre':\n",
        "        padded_seq = padding_elements + seq\n",
        "      else:  # padding == 'post'\n",
        "        padded_seq = seq + padding_elements\n",
        "    else:\n",
        "      padded_seq = seq[:maxlen]  # Truncate if longer than maxlen\n",
        "\n",
        "    padded_sequences.append(padded_seq)\n",
        "  return np.array(padded_sequences, dtype=dtype)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "4qKCxbMOcDeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# 4. Pad Sequences for Uniform Length (Modified)\n",
        "max_seq_length = max(len(seq) for seq in sequences)\n",
        "padded_sequences = custom_pad_sequences(sequences, maxlen=max_seq_length, padding='post', dtype='float32')\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "f1Fi2NuO5dMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8dxVC8Ykv52",
        "outputId": "6dc7563f-73f3-4c81-90a5-0e3be914a9d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8750 - loss: 0.5874\n",
            "Test Accuracy: 0.8750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWYDwF1ak7Dq",
        "outputId": "6bd01aa6-0775-4ec3-c8f5-5ceb0f60862c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# output 1 sequence"
      ],
      "metadata": {
        "id": "Bw11F1jePWqA"
      }
    },
    {
      "source": [
        "# 5. Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "model = Sequential([\n",
        "    Masking(mask_value=0.0, input_shape=(max_seq_length, 2)),  # Corrected input shape to (max_seq_length, 2)\n",
        "    Bidirectional(LSTM(128, return_sequences=True)),\n",
        "    Bidirectional(LSTM(64, return_sequences=True)),\n",
        "    Bidirectional(LSTM(32)), #Added this LSTM layer without return_sequences=True.\n",
        "    #This will return the output from the last timestep in the Bidirectional LSTM.\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(len(set(labels)), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 8. Train with Early Stopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=16,\n",
        "          validation_data=(X_test, y_test),\n",
        "          callbacks=[early_stop])"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "oXLPwUOAHCVL",
        "outputId": "7fd6e2a1-986f-4097-a7ce-366a0823f277"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/masking.py:47: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Argument `output` must have rank (ndim) `target.ndim - 1`. Received: target.shape=(16,), output.shape=(16, 33, 4)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-0067e337334c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# 8. Train with Early Stopping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mearly_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m model.fit(X_train, y_train, epochs=100, batch_size=16, \n\u001b[0m\u001b[1;32m     20\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m           callbacks=[early_stop])\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/nn.py\u001b[0m in \u001b[0;36msparse_categorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m    723\u001b[0m         )\n\u001b[1;32m    724\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    726\u001b[0m             \u001b[0;34m\"Argument `output` must have rank (ndim) `target.ndim - 1`. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0;34m\"Received: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Argument `output` must have rank (ndim) `target.ndim - 1`. Received: target.shape=(16,), output.shape=(16, 33, 4)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# label sequence output"
      ],
      "metadata": {
        "id": "esDNUrheSJsn"
      }
    },
    {
      "source": [
        "# 5. Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Duplicate labels for each timestep in the sequence\n",
        "y_train_repeated = np.repeat(y_train[:, np.newaxis], max_seq_length, axis=1)\n",
        "y_test_repeated = np.repeat(y_test[:, np.newaxis], max_seq_length, axis=1)\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Masking(mask_value=0.0, input_shape=(max_seq_length, 2)),  # Corrected input shape to (max_seq_length, 2)\n",
        "    Bidirectional(LSTM(128, return_sequences=True)),\n",
        "    Bidirectional(LSTM(64, return_sequences=True)),\n",
        "    Bidirectional(LSTM(32, return_sequences=True)),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    TimeDistributed(Dense(len(set(labels)), activation='softmax')) # Wrap the final Dense layer with TimeDistributed\n",
        "])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 8. Train with Early Stopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "model.fit(X_train, y_train_repeated, epochs=100, batch_size=16, # Use the repeated labels for training\n",
        "          validation_data=(X_test, y_test_repeated), # Use the repeated labels for validation\n",
        "          callbacks=[early_stop])\n"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8bI8-zePGva",
        "outputId": "6c3fc036-6781-413b-9a86-f035bb34414d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 751ms/step - accuracy: 0.4316 - loss: 1.3737 - val_accuracy: 0.4413 - val_loss: 1.2762\n",
            "Epoch 2/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 158ms/step - accuracy: 0.5225 - loss: 1.2074 - val_accuracy: 0.4962 - val_loss: 1.1187\n",
            "Epoch 3/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 166ms/step - accuracy: 0.5184 - loss: 1.1082 - val_accuracy: 0.5114 - val_loss: 1.0299\n",
            "Epoch 4/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 243ms/step - accuracy: 0.5513 - loss: 1.0023 - val_accuracy: 0.5227 - val_loss: 0.9749\n",
            "Epoch 5/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 252ms/step - accuracy: 0.5631 - loss: 0.9225 - val_accuracy: 0.5246 - val_loss: 0.9257\n",
            "Epoch 6/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 377ms/step - accuracy: 0.5686 - loss: 0.8706 - val_accuracy: 0.5284 - val_loss: 0.8915\n",
            "Epoch 7/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 316ms/step - accuracy: 0.6265 - loss: 0.7944 - val_accuracy: 0.5795 - val_loss: 0.8401\n",
            "Epoch 8/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 157ms/step - accuracy: 0.6593 - loss: 0.7715 - val_accuracy: 0.6477 - val_loss: 0.8243\n",
            "Epoch 9/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 156ms/step - accuracy: 0.6804 - loss: 0.7105 - val_accuracy: 0.6269 - val_loss: 0.7640\n",
            "Epoch 10/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 178ms/step - accuracy: 0.8172 - loss: 0.5460 - val_accuracy: 0.7386 - val_loss: 0.6495\n",
            "Epoch 11/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 198ms/step - accuracy: 0.8466 - loss: 0.4865 - val_accuracy: 0.7708 - val_loss: 0.6174\n",
            "Epoch 12/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 162ms/step - accuracy: 0.9050 - loss: 0.4142 - val_accuracy: 0.8182 - val_loss: 0.5232\n",
            "Epoch 13/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - accuracy: 0.9570 - loss: 0.2589 - val_accuracy: 0.8163 - val_loss: 0.4902\n",
            "Epoch 14/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 170ms/step - accuracy: 0.9743 - loss: 0.1606 - val_accuracy: 0.8617 - val_loss: 0.4440\n",
            "Epoch 15/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 161ms/step - accuracy: 0.9758 - loss: 0.1194 - val_accuracy: 0.8750 - val_loss: 0.5629\n",
            "Epoch 16/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 282ms/step - accuracy: 0.9239 - loss: 0.2594 - val_accuracy: 0.8750 - val_loss: 0.4108\n",
            "Epoch 17/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 316ms/step - accuracy: 0.9699 - loss: 0.1047 - val_accuracy: 0.8769 - val_loss: 0.5039\n",
            "Epoch 18/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 490ms/step - accuracy: 0.9490 - loss: 0.1631 - val_accuracy: 0.6989 - val_loss: 0.8668\n",
            "Epoch 19/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - accuracy: 0.9276 - loss: 0.2201 - val_accuracy: 0.7727 - val_loss: 0.7210\n",
            "Epoch 20/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - accuracy: 0.9006 - loss: 0.2194 - val_accuracy: 0.8390 - val_loss: 0.4688\n",
            "Epoch 21/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 237ms/step - accuracy: 0.9707 - loss: 0.1197 - val_accuracy: 0.9072 - val_loss: 0.3200\n",
            "Epoch 22/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - accuracy: 0.9683 - loss: 0.1162 - val_accuracy: 0.8750 - val_loss: 0.4204\n",
            "Epoch 23/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 151ms/step - accuracy: 0.9779 - loss: 0.0828 - val_accuracy: 0.8769 - val_loss: 0.3444\n",
            "Epoch 24/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 155ms/step - accuracy: 0.9876 - loss: 0.0674 - val_accuracy: 0.8769 - val_loss: 0.4435\n",
            "Epoch 25/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - accuracy: 0.9434 - loss: 0.2121 - val_accuracy: 0.7841 - val_loss: 0.4069\n",
            "Epoch 26/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - accuracy: 0.9931 - loss: 0.0562 - val_accuracy: 0.8144 - val_loss: 0.5681\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c9f08584750>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "source": [
        "# 5. Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Duplicate labels for each timestep in the sequence\n",
        "y_train_repeated = np.repeat(y_train[:, np.newaxis], max_seq_length, axis=1)\n",
        "y_test_repeated = np.repeat(y_test[:, np.newaxis], max_seq_length, axis=1)\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Masking(mask_value=0.0, input_shape=(max_seq_length, 2)),  # Corrected input shape to (max_seq_length, 2)\n",
        "    Bidirectional(LSTM(128, return_sequences=True)),\n",
        "    Bidirectional(LSTM(64, return_sequences=True)),\n",
        "    Bidirectional(LSTM(32, return_sequences=True)),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    TimeDistributed(Dense(2, activation='linear'))  # Output layer for finger ID and duration\n",
        "])\n",
        "\n",
        "model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
        "\n",
        "# 8. Train with Early Stopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=16,\n",
        "          validation_data=(X_test, y_test),\n",
        "          callbacks=[early_stop])\n"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "X9Kzr5PASOUu",
        "outputId": "35b61572-78e9-4561-824c-d185525320bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/masking.py:47: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Dimensions must be equal, but are 16 and 2 for '{{node compile_loss/mse/sub}} = Sub[T=DT_FLOAT](compile_loss/mse/Cast, sequential_11_1/time_distributed_15_1/transpose_2)' with input shapes: [16], [16,33,2].",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-c881d23dd8d9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m model.fit(X_train, y_train, epochs=100, batch_size=16, \n\u001b[0m\u001b[1;32m     26\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m           callbacks=[early_stop])\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/losses/losses.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m   1677\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1678\u001b[0m     \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqueeze_or_expand_to_same_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1679\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 16 and 2 for '{{node compile_loss/mse/sub}} = Sub[T=DT_FLOAT](compile_loss/mse/Cast, sequential_11_1/time_distributed_15_1/transpose_2)' with input shapes: [16], [16,33,2]."
          ]
        }
      ]
    },
    {
      "source": [
        "# 5. Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape y_train and y_test to (num_samples, 1)\n",
        "y_train = y_train.reshape(-1, 1)\n",
        "y_test = y_test.reshape(-1, 1)\n",
        "\n",
        "# Duplicate labels for each timestep in the sequence\n",
        "y_train_repeated = np.repeat(y_train, max_seq_length, axis=1)\n",
        "y_test_repeated = np.repeat(y_test, max_seq_length, axis=1)\n",
        "\n",
        "# Reshape to (num_samples, sequence_length, num_features)\n",
        "y_train_repeated = y_train_repeated[:, :, np.newaxis]  # Add a new axis for features\n",
        "y_test_repeated = y_test_repeated[:, :, np.newaxis]  # Add a new axis for features\n",
        "\n",
        "# Add duration information to y_train_repeated and y_test_repeated\n",
        "# Assuming your padded_sequences have shape (num_samples, sequence_length, 2)\n",
        "# where the last dimension contains (finger_id, duration)\n",
        "# Use X_train and X_test instead of padded_sequences to match the shapes\n",
        "y_train_repeated = np.concatenate([y_train_repeated, X_train[:, :, 1:]], axis=2)  # Concatenate duration\n",
        "y_test_repeated = np.concatenate([y_test_repeated, X_test[:, :, 1:]], axis=2)  # Concatenate duration\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Masking(mask_value=0.0, input_shape=(max_seq_length, 2)),  # Corrected input shape to (max_seq_length, 2)\n",
        "    Bidirectional(LSTM(128, return_sequences=True)),\n",
        "    Bidirectional(LSTM(64, return_sequences=True)),\n",
        "    Bidirectional(LSTM(32, return_sequences=True)),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    TimeDistributed(Dense(2, activation='linear'))  # Output layer for finger ID and duration\n",
        "])\n",
        "\n",
        "model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
        "\n",
        "# 8. Train with Early Stopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "model.fit(X_train, y_train_repeated, epochs=100, batch_size=16,\n",
        "          validation_data=(X_test, y_test_repeated),\n",
        "          callbacks=[early_stop])"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vnKiQ9CTtWW",
        "outputId": "2594d698-3d04-456d-f589-af03cd418b60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/masking.py:47: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 896ms/step - loss: 1.5458 - mae: 0.8494 - val_loss: 1.1528 - val_mae: 0.7930\n",
            "Epoch 2/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 151ms/step - loss: 0.9575 - mae: 0.7128 - val_loss: 1.0872 - val_mae: 0.8273\n",
            "Epoch 3/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.8817 - mae: 0.7105 - val_loss: 1.0579 - val_mae: 0.7519\n",
            "Epoch 4/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 157ms/step - loss: 0.8282 - mae: 0.6525 - val_loss: 1.0406 - val_mae: 0.7591\n",
            "Epoch 5/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 187ms/step - loss: 0.8245 - mae: 0.6557 - val_loss: 1.0032 - val_mae: 0.7388\n",
            "Epoch 6/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 161ms/step - loss: 0.8956 - mae: 0.6863 - val_loss: 0.9897 - val_mae: 0.7492\n",
            "Epoch 7/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.8404 - mae: 0.6783 - val_loss: 1.0281 - val_mae: 0.7500\n",
            "Epoch 8/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 159ms/step - loss: 0.7595 - mae: 0.6222 - val_loss: 0.9702 - val_mae: 0.7245\n",
            "Epoch 9/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 159ms/step - loss: 0.7573 - mae: 0.6158 - val_loss: 0.9367 - val_mae: 0.7093\n",
            "Epoch 10/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 154ms/step - loss: 0.6954 - mae: 0.5930 - val_loss: 0.8970 - val_mae: 0.7078\n",
            "Epoch 11/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 159ms/step - loss: 0.6098 - mae: 0.5678 - val_loss: 0.7415 - val_mae: 0.6022\n",
            "Epoch 12/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 154ms/step - loss: 0.5365 - mae: 0.5262 - val_loss: 0.5848 - val_mae: 0.5194\n",
            "Epoch 13/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 173ms/step - loss: 0.6099 - mae: 0.5157 - val_loss: 0.6966 - val_mae: 0.5908\n",
            "Epoch 14/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 191ms/step - loss: 0.5820 - mae: 0.5211 - val_loss: 0.9170 - val_mae: 0.5702\n",
            "Epoch 15/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 570ms/step - loss: 0.4783 - mae: 0.4446 - val_loss: 0.5533 - val_mae: 0.4974\n",
            "Epoch 16/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 165ms/step - loss: 0.3881 - mae: 0.4213 - val_loss: 0.6139 - val_mae: 0.5389\n",
            "Epoch 17/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 328ms/step - loss: 0.4782 - mae: 0.4646 - val_loss: 0.5092 - val_mae: 0.4033\n",
            "Epoch 18/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - loss: 0.3395 - mae: 0.3788 - val_loss: 0.4872 - val_mae: 0.3756\n",
            "Epoch 19/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.2937 - mae: 0.3375 - val_loss: 0.3478 - val_mae: 0.3403\n",
            "Epoch 20/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.2709 - mae: 0.3219 - val_loss: 0.3625 - val_mae: 0.3397\n",
            "Epoch 21/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.2377 - mae: 0.2915 - val_loss: 0.3310 - val_mae: 0.3314\n",
            "Epoch 22/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 180ms/step - loss: 0.2860 - mae: 0.3166 - val_loss: 0.3413 - val_mae: 0.3344\n",
            "Epoch 23/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 264ms/step - loss: 0.2763 - mae: 0.3148 - val_loss: 0.3093 - val_mae: 0.3151\n",
            "Epoch 24/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 158ms/step - loss: 0.2777 - mae: 0.3143 - val_loss: 0.2784 - val_mae: 0.2818\n",
            "Epoch 25/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 155ms/step - loss: 0.2236 - mae: 0.2695 - val_loss: 0.2852 - val_mae: 0.2890\n",
            "Epoch 26/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 203ms/step - loss: 0.2640 - mae: 0.2975 - val_loss: 0.2959 - val_mae: 0.2941\n",
            "Epoch 27/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 258ms/step - loss: 0.2343 - mae: 0.2726 - val_loss: 0.2812 - val_mae: 0.2780\n",
            "Epoch 28/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 312ms/step - loss: 0.2419 - mae: 0.2797 - val_loss: 0.2681 - val_mae: 0.2695\n",
            "Epoch 29/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.2414 - mae: 0.2765 - val_loss: 0.2845 - val_mae: 0.2860\n",
            "Epoch 30/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - loss: 0.2378 - mae: 0.2724 - val_loss: 0.2738 - val_mae: 0.2834\n",
            "Epoch 31/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.2024 - mae: 0.2466 - val_loss: 0.2493 - val_mae: 0.2584\n",
            "Epoch 32/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 155ms/step - loss: 0.2210 - mae: 0.2615 - val_loss: 0.2741 - val_mae: 0.2818\n",
            "Epoch 33/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 156ms/step - loss: 0.2206 - mae: 0.2578 - val_loss: 0.2394 - val_mae: 0.2491\n",
            "Epoch 34/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 157ms/step - loss: 0.2236 - mae: 0.2604 - val_loss: 0.2804 - val_mae: 0.2948\n",
            "Epoch 35/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 0.2227 - mae: 0.2615 - val_loss: 0.2617 - val_mae: 0.2736\n",
            "Epoch 36/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.2132 - mae: 0.2531 - val_loss: 0.2315 - val_mae: 0.2384\n",
            "Epoch 37/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 151ms/step - loss: 0.1942 - mae: 0.2359 - val_loss: 0.2616 - val_mae: 0.2742\n",
            "Epoch 38/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.2153 - mae: 0.2558 - val_loss: 0.2622 - val_mae: 0.2809\n",
            "Epoch 39/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 155ms/step - loss: 0.2248 - mae: 0.2591 - val_loss: 0.2381 - val_mae: 0.2512\n",
            "Epoch 40/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 0.2291 - mae: 0.2607 - val_loss: 0.2516 - val_mae: 0.2689\n",
            "Epoch 41/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 154ms/step - loss: 0.2018 - mae: 0.2375 - val_loss: 0.2392 - val_mae: 0.2522\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c9ef222abd0>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "source": [
        "# 9. Evaluate Model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "id": "TBAjVfBcGc4T",
        "outputId": "0b004a49-f4fa-4b82-c0d2-abb95ff276cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OperatorNotAllowedInGraphError",
          "evalue": "Exception encountered when calling TimeDistributed.call().\n\n\u001b[1mUsing a symbolic `tf.Tensor` as a Python `bool` is not allowed. You can attempt the following resolutions to the problem: If you are running in Graph mode, use Eager execution mode or decorate this function with @tf.function. If you are using AutoGraph, you can try decorating this function with @tf.function. If that does not work, then you may be using an unsupported feature or your source code may not be visible to AutoGraph. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/limitations.md#access-to-source-code for more information.\u001b[0m\n\nArguments received by TimeDistributed.call():\n  • inputs=tf.Tensor(shape=(None, 33, 64), dtype=float32)\n  • training=False\n  • mask=tf.Tensor(shape=(None, 33), dtype=bool)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-61f911869286>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 9. Evaluate Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Test Accuracy: {accuracy:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_handler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m: Exception encountered when calling TimeDistributed.call().\n\n\u001b[1mUsing a symbolic `tf.Tensor` as a Python `bool` is not allowed. You can attempt the following resolutions to the problem: If you are running in Graph mode, use Eager execution mode or decorate this function with @tf.function. If you are using AutoGraph, you can try decorating this function with @tf.function. If that does not work, then you may be using an unsupported feature or your source code may not be visible to AutoGraph. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/limitations.md#access-to-source-code for more information.\u001b[0m\n\nArguments received by TimeDistributed.call():\n  • inputs=tf.Tensor(shape=(None, 33, 64), dtype=float32)\n  • training=False\n  • mask=tf.Tensor(shape=(None, 33), dtype=bool)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Save Model\n",
        "model.save(\"lstm_finger_Sq_model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0REUh7ajHMkM",
        "outputId": "cdad4252-fcca-44e1-c636-0db7b4ee2ac2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UfQrqh7kUt4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This give linear output"
      ],
      "metadata": {
        "id": "u_Twf_p2iDR-"
      }
    },
    {
      "source": [
        "# 5. Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape y_train and y_test to (num_samples, 1)\n",
        "y_train = y_train.reshape(-1, 1)\n",
        "y_test = y_test.reshape(-1, 1)\n",
        "\n",
        "# Duplicate labels for each timestep in the sequence\n",
        "y_train_repeated = np.repeat(y_train, max_seq_length, axis=1)\n",
        "y_test_repeated = np.repeat(y_test, max_seq_length, axis=1)\n",
        "\n",
        "# Reshape to (num_samples, sequence_length, num_features)\n",
        "y_train_repeated = y_train_repeated[:, :, np.newaxis]  # Add a new axis for features\n",
        "y_test_repeated = y_test_repeated[:, :, np.newaxis]  # Add a new axis for features\n",
        "\n",
        "# Add duration information to y_train_repeated and y_test_repeated\n",
        "# Assuming your padded_sequences have shape (num_samples, sequence_length, 2)\n",
        "# where the last dimension contains (finger_id, duration)\n",
        "# Use X_train and X_test instead of padded_sequences to match the shapes\n",
        "y_train_repeated = np.concatenate([y_train_repeated, X_train[:, :, 1:]], axis=2)  # Concatenate duration\n",
        "y_test_repeated = np.concatenate([y_test_repeated, X_test[:, :, 1:]], axis=2)  # Concatenate duration\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Masking(mask_value=0.0, input_shape=(max_seq_length, 2)),  # Corrected input shape to (max_seq_length, 2)\n",
        "    Bidirectional(LSTM(128, return_sequences=True)),\n",
        "    Bidirectional(LSTM(64, return_sequences=True)),\n",
        "    Bidirectional(LSTM(32, return_sequences=True)),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    TimeDistributed(Dense(2, activation='linear'))  # Output layer for finger ID and duration\n",
        "])\n",
        "\n",
        "model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
        "\n",
        "# 8. Train with Early Stopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "model.fit(X_train, y_train_repeated, epochs=100, batch_size=16,\n",
        "          validation_data=(X_test, y_test_repeated),\n",
        "          callbacks=[early_stop])"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b5569a2-cef9-41bb-e7ed-c346d189365c",
        "id": "Mu_14KsfUuKC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/masking.py:47: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 680ms/step - loss: 1.9941 - mse: 1.9941 - val_loss: 1.2536 - val_mse: 1.2536\n",
            "Epoch 2/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 267ms/step - loss: 1.0505 - mse: 1.0505 - val_loss: 1.1309 - val_mse: 1.1309\n",
            "Epoch 3/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 256ms/step - loss: 0.9406 - mse: 0.9406 - val_loss: 1.0770 - val_mse: 1.0770\n",
            "Epoch 4/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 157ms/step - loss: 0.9341 - mse: 0.9341 - val_loss: 1.1047 - val_mse: 1.1047\n",
            "Epoch 5/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 159ms/step - loss: 0.8882 - mse: 0.8882 - val_loss: 1.0687 - val_mse: 1.0687\n",
            "Epoch 6/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 160ms/step - loss: 0.7702 - mse: 0.7702 - val_loss: 1.0241 - val_mse: 1.0241\n",
            "Epoch 7/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 295ms/step - loss: 0.8532 - mse: 0.8532 - val_loss: 1.0212 - val_mse: 1.0212\n",
            "Epoch 8/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 264ms/step - loss: 0.8005 - mse: 0.8005 - val_loss: 1.0210 - val_mse: 1.0210\n",
            "Epoch 9/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 157ms/step - loss: 0.8202 - mse: 0.8202 - val_loss: 1.0572 - val_mse: 1.0572\n",
            "Epoch 10/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 161ms/step - loss: 0.8570 - mse: 0.8570 - val_loss: 1.0393 - val_mse: 1.0393\n",
            "Epoch 11/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 157ms/step - loss: 0.8480 - mse: 0.8480 - val_loss: 1.0209 - val_mse: 1.0209\n",
            "Epoch 12/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 320ms/step - loss: 0.8925 - mse: 0.8925 - val_loss: 1.0121 - val_mse: 1.0121\n",
            "Epoch 13/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - loss: 0.8134 - mse: 0.8134 - val_loss: 1.0240 - val_mse: 1.0240\n",
            "Epoch 14/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 275ms/step - loss: 0.8019 - mse: 0.8019 - val_loss: 1.0175 - val_mse: 1.0175\n",
            "Epoch 15/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.7702 - mse: 0.7702 - val_loss: 1.0003 - val_mse: 1.0003\n",
            "Epoch 16/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 254ms/step - loss: 0.8087 - mse: 0.8087 - val_loss: 1.0392 - val_mse: 1.0392\n",
            "Epoch 17/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 271ms/step - loss: 0.7379 - mse: 0.7379 - val_loss: 0.9063 - val_mse: 0.9063\n",
            "Epoch 18/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 169ms/step - loss: 0.6124 - mse: 0.6124 - val_loss: 0.9362 - val_mse: 0.9362\n",
            "Epoch 19/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 0.5574 - mse: 0.5574 - val_loss: 0.8737 - val_mse: 0.8737\n",
            "Epoch 20/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 0.5801 - mse: 0.5801 - val_loss: 0.5575 - val_mse: 0.5575\n",
            "Epoch 21/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 156ms/step - loss: 0.3773 - mse: 0.3773 - val_loss: 0.6634 - val_mse: 0.6634\n",
            "Epoch 22/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 154ms/step - loss: 0.3463 - mse: 0.3463 - val_loss: 0.4719 - val_mse: 0.4719\n",
            "Epoch 23/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 164ms/step - loss: 0.2971 - mse: 0.2971 - val_loss: 0.4318 - val_mse: 0.4318\n",
            "Epoch 24/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 159ms/step - loss: 0.4943 - mse: 0.4943 - val_loss: 1.2792 - val_mse: 1.2792\n",
            "Epoch 25/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 166ms/step - loss: 0.5370 - mse: 0.5370 - val_loss: 0.4482 - val_mse: 0.4482\n",
            "Epoch 26/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - loss: 0.3966 - mse: 0.3966 - val_loss: 0.3891 - val_mse: 0.3891\n",
            "Epoch 27/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 161ms/step - loss: 0.3167 - mse: 0.3167 - val_loss: 0.4144 - val_mse: 0.4144\n",
            "Epoch 28/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 165ms/step - loss: 0.3142 - mse: 0.3142 - val_loss: 0.3322 - val_mse: 0.3322\n",
            "Epoch 29/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 246ms/step - loss: 0.2500 - mse: 0.2500 - val_loss: 0.3575 - val_mse: 0.3575\n",
            "Epoch 30/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 281ms/step - loss: 0.2899 - mse: 0.2899 - val_loss: 0.5415 - val_mse: 0.5415\n",
            "Epoch 31/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 247ms/step - loss: 0.2892 - mse: 0.2892 - val_loss: 0.3045 - val_mse: 0.3045\n",
            "Epoch 32/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 159ms/step - loss: 0.2883 - mse: 0.2883 - val_loss: 0.3387 - val_mse: 0.3387\n",
            "Epoch 33/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 157ms/step - loss: 0.2551 - mse: 0.2551 - val_loss: 0.3959 - val_mse: 0.3959\n",
            "Epoch 34/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 153ms/step - loss: 0.2555 - mse: 0.2555 - val_loss: 0.3523 - val_mse: 0.3523\n",
            "Epoch 35/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 157ms/step - loss: 0.2591 - mse: 0.2591 - val_loss: 0.5041 - val_mse: 0.5041\n",
            "Epoch 36/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 159ms/step - loss: 0.2607 - mse: 0.2607 - val_loss: 0.2534 - val_mse: 0.2534\n",
            "Epoch 37/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 153ms/step - loss: 0.2262 - mse: 0.2262 - val_loss: 0.3581 - val_mse: 0.3581\n",
            "Epoch 38/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 153ms/step - loss: 0.2640 - mse: 0.2640 - val_loss: 0.2935 - val_mse: 0.2935\n",
            "Epoch 39/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.2341 - mse: 0.2341 - val_loss: 0.2694 - val_mse: 0.2694\n",
            "Epoch 40/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.2484 - mse: 0.2484 - val_loss: 0.2528 - val_mse: 0.2528\n",
            "Epoch 41/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - loss: 0.2409 - mse: 0.2409 - val_loss: 0.2548 - val_mse: 0.2548\n",
            "Epoch 42/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - loss: 0.2264 - mse: 0.2264 - val_loss: 0.2754 - val_mse: 0.2754\n",
            "Epoch 43/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 256ms/step - loss: 0.2299 - mse: 0.2299 - val_loss: 0.2630 - val_mse: 0.2630\n",
            "Epoch 44/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 254ms/step - loss: 0.2358 - mse: 0.2358 - val_loss: 0.2408 - val_mse: 0.2408\n",
            "Epoch 45/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 264ms/step - loss: 0.1983 - mse: 0.1983 - val_loss: 0.2513 - val_mse: 0.2513\n",
            "Epoch 46/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - loss: 0.2026 - mse: 0.2026 - val_loss: 0.2418 - val_mse: 0.2418\n",
            "Epoch 47/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - loss: 0.2033 - mse: 0.2033 - val_loss: 0.2218 - val_mse: 0.2218\n",
            "Epoch 48/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.1926 - mse: 0.1926 - val_loss: 0.2556 - val_mse: 0.2556\n",
            "Epoch 49/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.1944 - mse: 0.1944 - val_loss: 0.2074 - val_mse: 0.2074\n",
            "Epoch 50/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 162ms/step - loss: 0.1902 - mse: 0.1902 - val_loss: 0.2280 - val_mse: 0.2280\n",
            "Epoch 51/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 155ms/step - loss: 0.2072 - mse: 0.2072 - val_loss: 0.3002 - val_mse: 0.3002\n",
            "Epoch 52/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - loss: 0.2136 - mse: 0.2136 - val_loss: 0.2729 - val_mse: 0.2729\n",
            "Epoch 53/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.1869 - mse: 0.1869 - val_loss: 0.2258 - val_mse: 0.2258\n",
            "Epoch 54/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.1944 - mse: 0.1944 - val_loss: 0.2102 - val_mse: 0.2102\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c9ef2171250>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Save Model\n",
        "model.save(\"lstm_finger_Sqmse_model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksHuL2ugU1x2",
        "outputId": "2a600171-6e4b-4a10-c7ee-34056eecf43c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7sy4NO9NU0zH"
      }
    },
    {
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "\n",
        "# Load the model and explicitly define the loss function\n",
        "model = load_model(\"lstm_finger_Sqmse_model.h5\", custom_objects={'mse': MeanSquaredError()})\n",
        "\n",
        "# 2. Function to preprocess the input sequence (same as before)\n",
        "def preprocess_input(sequence):\n",
        "    \"\"\"Preprocesses a raw sequence for prediction.\n",
        "\n",
        "    Args:\n",
        "        sequence: A list of (finger_id, duration) tuples representing the sequence.\n",
        "\n",
        "    Returns:\n",
        "        A padded NumPy array representing the sequence.\n",
        "    \"\"\"\n",
        "    finger_ids = [int(pair[0]) for pair in sequence]\n",
        "    durations = [pair[1] for pair in sequence]\n",
        "    input_sequence = list(zip(finger_ids, durations))\n",
        "\n",
        "    # Pad the sequence to match the model's input shape\n",
        "    padded_sequence = pad_sequences([input_sequence], maxlen=max_seq_length, padding='post', dtype='float32')\n",
        "    return padded_sequence\n",
        "\n",
        "# 3. Example new input sequence\n",
        "new_sequence = [(1, 0.5), (2, 0.3), (3, 0.2)]\n",
        "\n",
        "# 4. Preprocess the input\n",
        "processed_sequence = preprocess_input(new_sequence)\n",
        "\n",
        "# 5. Get model predictions\n",
        "predictions = model.predict(processed_sequence)\n",
        "\n",
        "# 6. Interpret the predictions\n",
        "# predictions will have shape (1, max_seq_length, 2)\n",
        "# - predictions[0, i, 0] represents the predicted finger ID for timestep i\n",
        "# - predictions[0, i, 1] represents the predicted duration for timestep i\n",
        "\n",
        "# Example: Print predictions for each timestep\n",
        "for i in range(max_seq_length):\n",
        "    finger_id = predictions[0, i, 0]\n",
        "    duration = predictions[0, i, 1]\n",
        "    print(f\"Timestep {i + 1}: Predicted Finger ID: {finger_id:.2f}, Predicted Duration: {duration:.2f}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlnNeHVRURep",
        "outputId": "6871a60b-78ab-4563-a88e-879d4e6a52b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "Timestep 1: Predicted Finger ID: 0.61, Predicted Duration: 0.04\n",
            "Timestep 2: Predicted Finger ID: 0.67, Predicted Duration: 0.03\n",
            "Timestep 3: Predicted Finger ID: 0.69, Predicted Duration: 0.01\n",
            "Timestep 4: Predicted Finger ID: 0.20, Predicted Duration: -0.01\n",
            "Timestep 5: Predicted Finger ID: 0.20, Predicted Duration: -0.01\n",
            "Timestep 6: Predicted Finger ID: 0.20, Predicted Duration: -0.01\n",
            "Timestep 7: Predicted Finger ID: 0.20, Predicted Duration: -0.01\n",
            "Timestep 8: Predicted Finger ID: 0.20, Predicted Duration: -0.01\n",
            "Timestep 9: Predicted Finger ID: 0.20, Predicted Duration: -0.01\n",
            "Timestep 10: Predicted Finger ID: 0.20, Predicted Duration: -0.01\n",
            "Timestep 11: Predicted Finger ID: 0.20, Predicted Duration: -0.01\n",
            "Timestep 12: Predicted Finger ID: 0.20, Predicted Duration: -0.01\n",
            "Timestep 13: Predicted Finger ID: 0.20, Predicted Duration: -0.01\n",
            "Timestep 14: Predicted Finger ID: 0.20, Predicted Duration: -0.01\n",
            "Timestep 15: Predicted Finger ID: 0.20, Predicted Duration: -0.01\n",
            "Timestep 16: Predicted Finger ID: 0.20, Predicted Duration: -0.01\n",
            "Timestep 17: Predicted Finger ID: 0.20, Predicted Duration: -0.01\n",
            "Timestep 18: Predicted Finger ID: 0.20, Predicted Duration: -0.01\n",
            "Timestep 19: Predicted Finger ID: 0.20, Predicted Duration: -0.01\n",
            "Timestep 20: Predicted Finger ID: 0.20, Predicted Duration: -0.01\n",
            "Timestep 21: Predicted Finger ID: 0.20, Predicted Duration: -0.01\n",
            "Timestep 22: Predicted Finger ID: 0.20, Predicted Duration: -0.01\n",
            "Timestep 23: Predicted Finger ID: 0.20, Predicted Duration: -0.01\n",
            "Timestep 24: Predicted Finger ID: 0.20, Predicted Duration: -0.01\n",
            "Timestep 25: Predicted Finger ID: 0.20, Predicted Duration: -0.01\n",
            "Timestep 26: Predicted Finger ID: 0.20, Predicted Duration: -0.01\n",
            "Timestep 27: Predicted Finger ID: 0.20, Predicted Duration: -0.01\n",
            "Timestep 28: Predicted Finger ID: 0.20, Predicted Duration: -0.01\n",
            "Timestep 29: Predicted Finger ID: 0.20, Predicted Duration: -0.01\n",
            "Timestep 30: Predicted Finger ID: 0.20, Predicted Duration: -0.01\n",
            "Timestep 31: Predicted Finger ID: 0.20, Predicted Duration: -0.01\n",
            "Timestep 32: Predicted Finger ID: 0.20, Predicted Duration: -0.01\n",
            "Timestep 33: Predicted Finger ID: 0.20, Predicted Duration: -0.01\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "import pickle\n",
        "\n",
        "# 1. Load the saved model\n",
        "model = load_model(\"lstm_finger_model.h5\")\n",
        "\n",
        "# 2. Load the label encoder\n",
        "with open('label_encoder_model.pkl', 'rb') as file:\n",
        "    label_encoder = pickle.load(file)\n",
        "\n",
        "# 3. Function to preprocess the input sequence\n",
        "def preprocess_input(sequence):\n",
        "  \"\"\"Preprocesses a raw sequence for prediction.\n",
        "\n",
        "  Args:\n",
        "    sequence: A list of (finger_id, duration) tuples representing the sequence.\n",
        "\n",
        "  Returns:\n",
        "    A padded NumPy array representing the sequence.\n",
        "  \"\"\"\n",
        "  finger_ids = [int(pair[0]) for pair in sequence]\n",
        "  durations = [pair[1] for pair in sequence]\n",
        "  input_sequence = list(zip(finger_ids, durations))\n",
        "\n",
        "  # Pad the sequence to match the model's input shape\n",
        "  # Assuming max_seq_length is defined or loaded from somewhere\n",
        "  padded_sequence = pad_sequences([input_sequence], maxlen=max_seq_length, padding='post', dtype='float32')\n",
        "  return padded_sequence\n",
        "\n",
        "# 4. Example new input sequence\n",
        "new_sequence = [(1, 0.5), (2, 0.3), (3, 0.2)]  # Replace with your actual sequence\n",
        "\n",
        "# 5. Preprocess the input\n",
        "processed_sequence = preprocess_input(new_sequence)\n",
        "\n",
        "# 6. Make prediction\n",
        "prediction = np.argmax(model.predict(processed_sequence), axis=1)\n",
        "\n",
        "print(prediction)\n",
        "\n",
        "# 7. Convert prediction back to label\n",
        "predicted_label = label_encoder.inverse_transform(prediction)[0]  # Use index 0\n",
        "\n",
        "# 8. Print the predicted gesture\n",
        "print(f\"Predicted Gesture: {predicted_label}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhHd7iDyNDd_",
        "outputId": "0b986de5-6ff5-4a58-87e0-0434a2e5d64a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "[2]\n",
            "Predicted Gesture: LikeMe\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "import pickle\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences  # Import pad_sequences\n",
        "\n",
        "# 1. Load the saved model\n",
        "model = load_model(\"lstm_finger_model.h5\")\n",
        "\n",
        "# 2. Load the label encoder\n",
        "with open('label_encoder_model.pkl', 'rb') as file:\n",
        "    label_encoder = pickle.load(file)\n",
        "\n",
        "# 3. Function to preprocess the input sequence\n",
        "def preprocess_input(sequence):\n",
        "  \"\"\"Preprocesses a raw sequence for prediction.\n",
        "\n",
        "  Args:\n",
        "    sequence: A list of (finger_id, duration) tuples representing the sequence.\n",
        "\n",
        "  Returns:\n",
        "    A padded NumPy array representing the sequence.\n",
        "  \"\"\"\n",
        "  finger_ids = [int(pair[0]) for pair in sequence]\n",
        "  durations = [pair[1] for pair in sequence]\n",
        "  input_sequence = list(zip(finger_ids, durations))\n",
        "\n",
        "  # Pad the sequence to match the model's input shape\n",
        "  # Assuming max_seq_length is defined or loaded from somewhere\n",
        "  padded_sequence = pad_sequences([input_sequence], maxlen=max_seq_length, padding='post', dtype='float32')\n",
        "  return padded_sequence\n",
        "\n",
        "# 4. List of input sequences\n",
        "sequences = [\n",
        "    [(1, 0.5), (2, 0.3), (3, 0.2)],\n",
        "    [(2, 0.4), (3, 0.6), (1, 0.3)],\n",
        "    [(3, 0.2), (1, 0.5), (2, 0.4)]\n",
        "    # Add more sequences as needed\n",
        "]\n",
        "\n",
        "# 5. Predict and print for each sequence\n",
        "for sequence in sequences:\n",
        "    processed_sequence = preprocess_input(sequence)\n",
        "    prediction = np.argmax(model.predict(processed_sequence), axis=1)\n",
        "    print(prediction)\n",
        "    # predicted_label = label_encoder.inverse_transform(prediction)[0]  # Use index 0\n",
        "    # print(f\"Sequence: {sequence}, Predicted Gesture: {predicted_label}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIxIQcEyNe_O",
        "outputId": "a7200abb-936e-4b6d-dab6-446183410b9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "[[0 3 3 2]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "[[3 3 3 2]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "[[3 3 3 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# sample"
      ],
      "metadata": {
        "id": "1yJvwJNCbRNz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x9QEzsCNbTCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Masking, TimeDistributed\n",
        "# ... (other imports)\n",
        "\n",
        "\n",
        "# 1. Reshape target data for next-step prediction\n",
        "y_train_shifted = np.zeros_like(X_train)  # Initialize with zeros\n",
        "y_test_shifted = np.zeros_like(X_test)\n",
        "\n",
        "for i in range(len(X_train)):\n",
        "    y_train_shifted[i, :-5] = X_train[i, 5:]  # Shift target by 5 steps\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "    y_test_shifted[i, :-5] = X_test[i, 5:]\n",
        "\n",
        "# 2. Modify model architecture for sequence prediction\n",
        "model = Sequential([\n",
        "    Masking(mask_value=0.0, input_shape=(max_seq_length, 2)),\n",
        "    LSTM(128, return_sequences=True),\n",
        "    LSTM(64, return_sequences=True),\n",
        "    LSTM(32, return_sequences=True),  # Return sequences for all timesteps\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    TimeDistributed(Dense(2, activation='linear'))  # Predict finger ID and duration\n",
        "])\n",
        "\n",
        "# 3. Compile and train the model\n",
        "model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
        "model.fit(X_train, y_train_shifted, epochs=50, batch_size=16,\n",
        "          validation_data=(X_test, y_test_shifted), callbacks=[early_stop])\n",
        "\n"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDDB_8DZbThG",
        "outputId": "f46858b3-10bc-4633-824f-d1636ef4f46d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 457ms/step - loss: 2.8193 - mae: 0.9732 - val_loss: 1.7813 - val_mae: 0.8518\n",
            "Epoch 2/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 2.1383 - mae: 0.8814 - val_loss: 1.5088 - val_mae: 0.7899\n",
            "Epoch 3/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 2.1504 - mae: 0.8788 - val_loss: 1.4344 - val_mae: 0.7455\n",
            "Epoch 4/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 1.8564 - mae: 0.8156 - val_loss: 1.3060 - val_mae: 0.7429\n",
            "Epoch 5/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 1.9352 - mae: 0.8282 - val_loss: 1.2549 - val_mae: 0.6866\n",
            "Epoch 6/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.9016 - mae: 0.8081 - val_loss: 1.1901 - val_mae: 0.6596\n",
            "Epoch 7/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 1.6289 - mae: 0.7392 - val_loss: 1.1446 - val_mae: 0.6425\n",
            "Epoch 8/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 1.5416 - mae: 0.7131 - val_loss: 1.1211 - val_mae: 0.6276\n",
            "Epoch 9/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 1.3676 - mae: 0.6660 - val_loss: 1.0985 - val_mae: 0.6249\n",
            "Epoch 10/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 1.4997 - mae: 0.7029 - val_loss: 1.0776 - val_mae: 0.6199\n",
            "Epoch 11/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 1.4947 - mae: 0.7037 - val_loss: 1.0527 - val_mae: 0.5986\n",
            "Epoch 12/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 1.3407 - mae: 0.6547 - val_loss: 1.0268 - val_mae: 0.5845\n",
            "Epoch 13/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 1.3912 - mae: 0.6471 - val_loss: 0.9983 - val_mae: 0.5727\n",
            "Epoch 14/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 1.3058 - mae: 0.6282 - val_loss: 0.9553 - val_mae: 0.5481\n",
            "Epoch 15/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.3063 - mae: 0.6106 - val_loss: 0.9214 - val_mae: 0.5324\n",
            "Epoch 16/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 1.3497 - mae: 0.6119 - val_loss: 0.8982 - val_mae: 0.5220\n",
            "Epoch 17/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - loss: 1.1342 - mae: 0.5561 - val_loss: 0.8877 - val_mae: 0.5162\n",
            "Epoch 18/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - loss: 1.1376 - mae: 0.5528 - val_loss: 0.8979 - val_mae: 0.5183\n",
            "Epoch 19/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 160ms/step - loss: 1.0197 - mae: 0.5145 - val_loss: 0.8959 - val_mae: 0.5131\n",
            "Epoch 20/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 1.3177 - mae: 0.5955 - val_loss: 0.8827 - val_mae: 0.5110\n",
            "Epoch 21/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 1.1418 - mae: 0.5452 - val_loss: 0.8986 - val_mae: 0.5171\n",
            "Epoch 22/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 1.1996 - mae: 0.5622 - val_loss: 0.8741 - val_mae: 0.5088\n",
            "Epoch 23/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.2351 - mae: 0.5717 - val_loss: 0.8619 - val_mae: 0.4993\n",
            "Epoch 24/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 1.2382 - mae: 0.5628 - val_loss: 0.8605 - val_mae: 0.4955\n",
            "Epoch 25/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 1.2290 - mae: 0.5630 - val_loss: 0.8589 - val_mae: 0.4942\n",
            "Epoch 26/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 1.2831 - mae: 0.5665 - val_loss: 0.8695 - val_mae: 0.5005\n",
            "Epoch 27/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 1.2331 - mae: 0.5527 - val_loss: 0.8825 - val_mae: 0.5131\n",
            "Epoch 28/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 1.2356 - mae: 0.5580 - val_loss: 0.9233 - val_mae: 0.5307\n",
            "Epoch 29/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 1.0612 - mae: 0.5207 - val_loss: 0.8909 - val_mae: 0.5180\n",
            "Epoch 30/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 1.1827 - mae: 0.5445 - val_loss: 0.8565 - val_mae: 0.4928\n",
            "Epoch 31/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 1.0670 - mae: 0.5163 - val_loss: 0.8344 - val_mae: 0.4927\n",
            "Epoch 32/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 1.0239 - mae: 0.5036 - val_loss: 0.8700 - val_mae: 0.5085\n",
            "Epoch 33/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 1.1251 - mae: 0.5363 - val_loss: 0.8325 - val_mae: 0.4814\n",
            "Epoch 34/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.9768 - mae: 0.4865 - val_loss: 0.8380 - val_mae: 0.4987\n",
            "Epoch 35/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 1.0980 - mae: 0.5144 - val_loss: 0.8591 - val_mae: 0.4988\n",
            "Epoch 36/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 1.1299 - mae: 0.5283 - val_loss: 0.8209 - val_mae: 0.4798\n",
            "Epoch 37/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 1.1098 - mae: 0.5152 - val_loss: 0.8171 - val_mae: 0.4740\n",
            "Epoch 38/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 1.0441 - mae: 0.4990 - val_loss: 0.8199 - val_mae: 0.4748\n",
            "Epoch 39/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 1.0882 - mae: 0.4958 - val_loss: 0.8361 - val_mae: 0.4881\n",
            "Epoch 40/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.0417 - mae: 0.5051 - val_loss: 0.8137 - val_mae: 0.4729\n",
            "Epoch 41/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 1.0634 - mae: 0.4991 - val_loss: 0.8154 - val_mae: 0.4715\n",
            "Epoch 42/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 153ms/step - loss: 0.9947 - mae: 0.4747 - val_loss: 0.8109 - val_mae: 0.4686\n",
            "Epoch 43/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 1.0306 - mae: 0.4838 - val_loss: 0.8437 - val_mae: 0.4913\n",
            "Epoch 44/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.9917 - mae: 0.4774 - val_loss: 0.8048 - val_mae: 0.4681\n",
            "Epoch 45/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 151ms/step - loss: 0.9098 - mae: 0.4460 - val_loss: 0.8082 - val_mae: 0.4643\n",
            "Epoch 46/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 1.0399 - mae: 0.4820 - val_loss: 0.8196 - val_mae: 0.4747\n",
            "Epoch 47/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 1.0547 - mae: 0.4833 - val_loss: 0.8303 - val_mae: 0.4824\n",
            "Epoch 48/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.0701 - mae: 0.4945 - val_loss: 0.8442 - val_mae: 0.4850\n",
            "Epoch 49/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.9961 - mae: 0.4735 - val_loss: 0.8266 - val_mae: 0.4722\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c9ef2979150>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xYRx6k2xc8Kv"
      }
    },
    {
      "source": [
        "# 3. Function to preprocess the input sequence\n",
        "def preprocess_input(sequence):\n",
        "  \"\"\"Preprocesses a raw sequence for prediction.\n",
        "\n",
        "  Args:\n",
        "    sequence: A list of (finger_id, duration) tuples representing the sequence.\n",
        "\n",
        "  Returns:\n",
        "    A padded NumPy array representing the sequence.\n",
        "  \"\"\"\n",
        "  finger_ids = [int(pair[0]) for pair in sequence]\n",
        "  durations = [pair[1] for pair in sequence]\n",
        "  input_sequence = list(zip(finger_ids, durations))\n",
        "\n",
        "  # Pad the sequence to match the model's input shape\n",
        "  # Assuming max_seq_length is defined or loaded from somewhere\n",
        "  padded_sequence = pad_sequences([input_sequence], maxlen=max_seq_length, padding='post', dtype='float32')\n",
        "  return padded_sequence"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "x80JSXEUc4r5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Prediction\n",
        "def predict_next_5_steps(input_sequence):\n",
        "    \"\"\"Predicts the next 5 steps of a sequence.\"\"\"\n",
        "    processed_sequence = preprocess_input(input_sequence)\n",
        "    predictions = model.predict(processed_sequence)\n",
        "    next_5_steps = predictions[0, -5:]  # Get last 5 predicted steps\n",
        "    return next_5_steps"
      ],
      "metadata": {
        "id": "pShITIbJbuMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "input_sequence = [(1, 0.5), (2, 0.3), (3, 0.2)]  # Example input\n",
        "predicted_steps = predict_next_5_steps(input_sequence)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "5zdV0ebXcBo8",
        "outputId": "d58c5d79-5c92-4a1d-c95a-f76fd2b276b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unrecognized data type: x=[(1, 0.5), (2, 0.3), (3, 0.2)] (of type <class 'list'>)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-731de320fb82>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Example input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredicted_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_next_5_steps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-71-b89900633fdd>\u001b[0m in \u001b[0;36mpredict_next_5_steps\u001b[0;34m(input_sequence)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#predictions = model.predict(processed_sequence)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mnext_5_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Get last 5 predicted steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/__init__.py\u001b[0m in \u001b[0;36mget_data_adapter\u001b[0;34m(x, y, sample_weight, batch_size, steps_per_epoch, shuffle, class_weight)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unrecognized data type: x={x} (of type {type(x)})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unrecognized data type: x=[(1, 0.5), (2, 0.3), (3, 0.2)] (of type <class 'list'>)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xeoKXHRmcD1R"
      }
    },
    {
      "source": [
        "def predict_next_5_steps(input_sequence):\n",
        "    \"\"\"Predicts the next 5 steps of a sequence and prints them.\"\"\"\n",
        "    processed_sequence = preprocess_input(input_sequence)\n",
        "    #predictions = model.predict(processed_sequence)\n",
        "\n",
        "    predictions = model.predict(input_sequence)\n",
        "    next_5_steps = predictions[0, -5:]  # Get last 5 predicted steps\n",
        "\n",
        "    print(\"Predicted Next 5 Steps:\")\n",
        "    for i, step in enumerate(next_5_steps):\n",
        "        finger_id = step[0]  # Assuming finger ID is in the first column\n",
        "        duration = step[1]  # Assuming duration is in the second column\n",
        "        print(f\"Step {i + 1}: Finger ID: {finger_id:.2f}, Duration: {duration:.2f}\")\n",
        "\n",
        "    return next_5_steps"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Wr-7Y0TNcDd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_5_steps(input_sequence):\n",
        "    \"\"\"Predicts the next 5 steps of a sequence and prints them.\"\"\"\n",
        "    processed_sequence = np.preprocess_input(input_sequence)\n",
        "    #predictions = model.predict(processed_sequence)\n",
        "\n",
        "    predictions = model.predict(input_sequence)\n",
        "    next_5_steps = predictions[0, -5:]  # Get last 5 predicted steps\n",
        "\n",
        "    print(\"Predicted Next 5 Steps:\")\n",
        "    for i, step in enumerate(next_5_steps):\n",
        "        finger_id = step[0]  # Assuming finger ID is in the first column\n",
        "        duration = step[1]  # Assuming duration is in the second column\n",
        "        print(f\"Step {i + 1}: Finger ID: {finger_id:.2f}, Duration: {duration:.2f}\")\n",
        "\n",
        "    return next_5_steps"
      ],
      "metadata": {
        "id": "u1vTaT_KgBWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequence = [(1, 0.5), (2, 0.3), (3, 0.2)]  # Example input\n",
        "predicted_steps = predict_next_5_steps(input_sequence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "TmYfnWX7gb_w",
        "outputId": "34210073-d5b0-4261-c319-c755288d3b46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'numpy' has no attribute 'preprocess_input'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-731de320fb82>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Example input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredicted_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_next_5_steps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-80-6c9ed7737b81>\u001b[0m in \u001b[0;36mpredict_next_5_steps\u001b[0;34m(input_sequence)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_next_5_steps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"\"\"Predicts the next 5 steps of a sequence and prints them.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprocessed_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m#predictions = model.predict(processed_sequence)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tester was removed in NumPy 1.25.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m         raise AttributeError(\"module {!r} has no attribute \"\n\u001b[0m\u001b[1;32m    334\u001b[0m                              \"{!r}\".format(__name__, attr))\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'preprocess_input'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Function to preprocess the input sequence\n",
        "def preprocess_input(sequence):\n",
        "  \"\"\"Preprocesses a raw sequence for prediction.\n",
        "\n",
        "  Args:\n",
        "    sequence: A list of (finger_id, duration) tuples representing the sequence.\n",
        "\n",
        "  Returns:\n",
        "    A padded NumPy array representing the sequence.\n",
        "  \"\"\"\n",
        "  finger_ids = [int(pair[0]) for pair in sequence]\n",
        "  durations = [pair[1] for pair in sequence]\n",
        "  input_sequence = list(zip(finger_ids, durations))\n",
        "\n",
        "  # Pad the sequence to match the model's input shape\n",
        "  # Assuming max_seq_length is defined or loaded from somewhere\n",
        "  padded_sequence = custom_pad_sequences([input_sequence], maxlen=max_seq_length, padding='post', dtype='float32')\n",
        "  return padded_sequence"
      ],
      "metadata": {
        "id": "AiMyASt2gNt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_pad_sequences(sequences, maxlen, padding='post', dtype='float32'):\n",
        "  \"\"\"Pads sequences with custom values based on label.\n",
        "\n",
        "  Args:\n",
        "    sequences: The list of sequences to pad.\n",
        "    maxlen: The desired length for all sequences.\n",
        "    padding: 'pre' or 'post' (default 'post').\n",
        "    dtype: The data type of the padded sequences.\n",
        "\n",
        "  Returns:\n",
        "    A NumPy array of padded sequences.\n",
        "  \"\"\"\n",
        "  padded_sequences = []\n",
        "  for i, seq in enumerate(sequences):  # Use enumerate to get index i\n",
        "    # Determine padding element based on corresponding label\n",
        "    label = labels[i]  # Get label for the sequence\n",
        "    if label == 'CallHarisVai':\n",
        "      padding_element = (\"2\", mean_duration)  # Using finger_map dictionary\n",
        "    elif label == 'Noise':\n",
        "      padding_element = (\"1\", mean_duration)  # Using finger_map dictionary\n",
        "    elif label == 'LikeMe':\n",
        "      padding_element = (\"3\", mean_duration)  # Using finger_map dictionary\n",
        "    elif label == 'ComeCLose':\n",
        "      padding_element = (\"8\", mean_duration)  # Using finger_map dictionary\n",
        "    else:\n",
        "      padding_element = (int(-1), mean_duration)  # Default padding element\n",
        "\n",
        "    # Pad the sequence to the desired length\n",
        "    if len(seq) < maxlen:\n",
        "      padding_elements = [padding_element] * (maxlen - len(seq))\n",
        "      if padding == 'pre':\n",
        "        padded_seq = padding_elements + seq\n",
        "      else:  # padding == 'post'\n",
        "        padded_seq = seq + padding_elements\n",
        "    else:\n",
        "      padded_seq = seq[:maxlen]  # Truncate if longer than maxlen\n",
        "\n",
        "    padded_sequences.append(padded_seq)\n",
        "  return np.array(padded_sequences, dtype=dtype)"
      ],
      "metadata": {
        "id": "BH90xl3zf_5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dIZqv4xwbt2F"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PZKBiitkcbwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ... (load your model and data)\n",
        "\n",
        "input_sequence = [(1, 0.5), (2, 0.3), (3, 0.2)]\n",
        "predicted_steps = predict_next_5_steps(input_sequence)\n",
        "\n",
        "# Extract predicted finger IDs and durations\n",
        "predicted_finger_ids = [step[0] for step in predicted_steps]\n",
        "predicted_durations = [step[1] for step in predicted_steps]\n",
        "\n",
        "# Plot the predictions\n",
        "plt.plot(predicted_finger_ids, label=\"Predicted Finger IDs\")\n",
        "plt.plot(predicted_durations, label=\"Predicted Durations\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "FvUmNAhtccOB",
        "outputId": "2236e66a-8a66-42ac-e2d8-380eaa4f2c99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
            "Predicted Next 5 Steps:\n",
            "Step 1: Finger ID: 1.50, Duration: -0.02\n",
            "Step 2: Finger ID: 1.50, Duration: -0.02\n",
            "Step 3: Finger ID: 1.50, Duration: -0.02\n",
            "Step 4: Finger ID: 1.50, Duration: -0.02\n",
            "Step 5: Finger ID: 1.50, Duration: -0.02\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "t5Qg8cPKbRF4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "label output"
      ],
      "metadata": {
        "id": "knoKuzoY-TuR"
      }
    },
    {
      "source": [
        "def preprocess_input(sequence):\n",
        "  \"\"\"Preprocesses a raw sequence for prediction.\n",
        "\n",
        "  Args:\n",
        "    sequence: A list of (finger_id, duration) tuples representing the sequence.\n",
        "\n",
        "  Returns:\n",
        "    A padded NumPy array representing the sequence.\n",
        "  \"\"\"\n",
        "  finger_ids = [int(pair[0]) for pair in sequence]\n",
        "  durations = [pair[1] for pair in sequence]\n",
        "  input_sequence = list(zip(finger_ids, durations))\n",
        "\n",
        "  # Pad the sequence to match the model's input shape\n",
        "  padded_sequence = pad_sequences([input_sequence], maxlen=max_seq_length, padding='post', dtype='float32')\n",
        "  return padded_sequence"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "FWTf6IhH2kSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Example new input sequence\n",
        "new_sequence = [(1, 0.5), (2, 0.3), (3, 0.2)]  # Replace with your actual sequence\n",
        "\n",
        "# Preprocess the input\n",
        "processed_sequence = preprocess_input(new_sequence)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "hqPBJ2wV2k_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Make prediction using the trained model\n",
        "prediction = np.argmax(model.predict(processed_sequence), axis=1)\n",
        "\n",
        "# Convert prediction back to label\n",
        "predicted_label = label_encoder.inverse_transform(prediction)[1]\n",
        "\n",
        "print(f\"Predicted Gesture: {predicted_label}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "2vn14TYR2lzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BsjoObL_bPz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PwvSFbuK2jmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZSs9ZnqH2jkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# label encoder"
      ],
      "metadata": {
        "id": "2ERsyPaKAoj1"
      }
    },
    {
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pickle\n",
        "\n",
        "# 1. Load the JSON Data (Assuming your data is in 'finger_sequences.json')\n",
        "with open(\"/content/finger_sequences.json\", \"r\") as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# 2. Prepare Labels\n",
        "labels = []\n",
        "for label, instances in data.items():\n",
        "    for _ in instances:  # We only need the labels, not the sequences\n",
        "        labels.append(label)\n",
        "\n",
        "# 3. Create and Fit Label Encoder\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(labels)\n",
        "\n",
        "# 4. Save the Label Encoder Model\n",
        "with open('label_encoder_model.pkl', 'wb') as file:\n",
        "    pickle.dump(label_encoder, file)\n",
        "\n",
        "print(\"Label encoder model saved to 'label_encoder_model.pkl'\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "fWcOYDxK8t4M",
        "outputId": "3656de49-1856-4f90-c799-efa35e587e38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label encoder model saved to 'label_encoder_model.pkl'\n"
          ]
        }
      ]
    }
  ]
}